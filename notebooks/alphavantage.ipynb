{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Apwv5kC86yl-"
      },
      "outputs": [],
      "source": [
        "!pip install -q pandas requests numpy scipy matplotlib dask scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CRYz5VTl7n4V"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import json\n",
        "import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "from scipy.stats import norm\n",
        "from datetime import datetime\n",
        "import os\n",
        "from decimal import Decimal, getcontext\n",
        "from multiprocessing import Pool\n",
        "\n",
        "import dask.dataframe as dd\n",
        "from dask.multiprocessing import get\n",
        "from dask import delayed\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from datetime import datetime\n",
        "# from sklearn.decomposition import PCA\n",
        "# from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2gv0QkvZ1b3m"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HWUmWWDhdskc"
      },
      "outputs": [],
      "source": [
        "class api_keys:\n",
        "    def __init__(self):\n",
        "        self.session = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "        print(self.session)\n",
        "        self.list = (\n",
        "           # \"LULKG4NIIZEJI6D2\",\n",
        "            \"YPOLRZMHBE5X9RKF\",\n",
        "            \"0C4JF7CVP6E14A6N\",\n",
        "            \"2YOP96J6F1HGCWPA\", # d2\n",
        "            \"3ZFGTFL238KPNCIY\", # d3\n",
        "            \"BXPI10OBKLNR0QQ8\", # d4\n",
        "            \"K8Q66F1AA7SDI317\", # d5\n",
        "            \"MC1DGRM5VJ6QQ4U3\", # mp1\n",
        "            \"KTPJ50N8JC8RKEGK\", # mp2\n",
        "            \"BC3IFP07ZZFZICJB\", # mp3\n",
        "            \"6Y3LB06GFNIU0OB1\", # mp4\n",
        "            \"60B1KPJJNGHZIDTC\", # bits 1\n",
        "            \"F0NZ9L4D8K4V3QAV\", # bits 2\n",
        "            \"8TV5GX40IW442BWY\", # bits 3\n",
        "            \"JDGY7JGQ2CGEZ6ER\", # d6\n",
        "            \"JT9NDBWC8VFGML3R\", # d7\n",
        "            \"SOYVTYHXUFZNH2A1\", # d8\n",
        "            \"G5MW2DYRW52UQKEO\", # d9\n",
        "            \"QBYT5P0FZ79JJBHT\", # d10\n",
        "            \"BY7HI8VLA18UUNVY\", #d11\n",
        "            \"WUD5HQDYD0KDK2MH\" #d12\n",
        "        )\n",
        "\n",
        "    def iterator(self):\n",
        "        for i in self.list:\n",
        "            yield i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fPhtAtn07iwa"
      },
      "outputs": [],
      "source": [
        "class getData:\n",
        "    \"\"\"\n",
        "    Use alpha vantage api to get SPY options data\n",
        "    \"\"\"\n",
        "    def __init__(self, symbol='SPY'):\n",
        "        self.api_keys = api_keys().list\n",
        "        self.key_iterator = iter(self.api_keys)\n",
        "        self.symbol = symbol\n",
        "\n",
        "    def _get_next_key(self):\n",
        "            try:\n",
        "                return next(self.key_iterator)\n",
        "            except StopIteration:\n",
        "                print(\"API keys exhausted.\")\n",
        "                return None\n",
        "\n",
        "    def _fetch_data(self, start_date, end_date):\n",
        "        query_date_range = pd.date_range(start=start_date, end=end_date)\n",
        "        data = []\n",
        "        current_key = self._get_next_key()\n",
        "        for query_date in query_date_range:\n",
        "            query_date_str = query_date.strftime('%Y-%m-%d')\n",
        "            retries = len(self.api_keys)\n",
        "            while retries > 0:\n",
        "                url = f'https://www.alphavantage.co/query?function=HISTORICAL_OPTIONS&symbol={self.symbol}&date={query_date_str}&apikey={current_key}'\n",
        "                response = requests.get(url)\n",
        "                d = response.json()\n",
        "                if 'message' in d and d['message'] == 'success':\n",
        "                    data.append(d['data'])\n",
        "                    print(f\"Fetched data for {query_date_str}\")\n",
        "                    break  # Successful fetch, move to next date\n",
        "                elif 'message' in d and d['message']!='success':\n",
        "                    print(\"No data found\")\n",
        "                    print(d)\n",
        "                    break # no data for date\n",
        "                else:\n",
        "                    print(f\"API key {current_key} exhausted: at {query_date_str}\")\n",
        "                    current_key = self._get_next_key()\n",
        "                    if current_key is None:\n",
        "                        print(f\"API keys exhausted at {query_date_str}\")\n",
        "                        break  # All keys exhausted, stop trying\n",
        "                    print(f\"Using key: {current_key}\")\n",
        "                retries -= 1\n",
        "        return data\n",
        "\n",
        "    def run(self, start_date, end_date, savefile):\n",
        "        data = self._fetch_data(start_date, end_date)\n",
        "        cwd = os.getcwd()\n",
        "        savefile = os.path.join(cwd, savefile)\n",
        "        with open(savefile, 'w') as f:\n",
        "            json.dump(data, f)\n",
        "\n",
        "class preprocessData:\n",
        "    \"\"\"\n",
        "    create a dataframe from the json file with required features\n",
        "    \"\"\"\n",
        "    def __init__(self, json_path):\n",
        "        self.json_path = json_path\n",
        "        getcontext().prec = 8\n",
        "\n",
        "    def _get_stats(self, obj):\n",
        "        exp_date = datetime.strptime(obj['expiration'], '%Y-%m-%d')\n",
        "        curr_date = datetime.strptime(obj['date'], '%Y-%m-%d')\n",
        "        tte = (exp_date - curr_date).days\n",
        "        tau = Decimal(tte) / Decimal(365)\n",
        "        delta = abs(float(obj['delta']))\n",
        "        if(delta==1):\n",
        "            delta = 0.999\n",
        "        elif(delta==0):\n",
        "            delta = 0.001\n",
        "        IV = np.float64(obj['implied_volatility'])\n",
        "        sigma = IV\n",
        "        q = Decimal('0.01')\n",
        "        N_inv = norm.ppf(delta * float(np.exp(float(q) * float(tau))))\n",
        "        sigma = Decimal(sigma)\n",
        "        m = (Decimal('0.5') * sigma**2 * tau) + (Decimal(N_inv) * sigma * Decimal(tau).sqrt())\n",
        "        current_date = curr_date.strftime('%Y-%m-%d')\n",
        "        expiry_date = exp_date.strftime('%Y-%m-%d')\n",
        "        return [current_date, expiry_date, tte, tau, delta, IV, sigma, N_inv, m]\n",
        "\n",
        "    @delayed\n",
        "    def delayed_stats(self, obj):\n",
        "        return self._get_stats(obj)\n",
        "\n",
        "    def fit(self):\n",
        "        with open(self.json_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        # results = [self.delayed_stats(d) for d in data]\n",
        "        # results = dd.from_delayed(results)\n",
        "        # df = results.compute(scheduler='processes')\n",
        "\n",
        "        # df = dd.from_pandas(df, npartitions=4)\n",
        "        # merge all sublists in data into one list\n",
        "        data = [item for sublist in data for item in sublist]\n",
        "        result = []\n",
        "        for d in data:\n",
        "            result.append(self._get_stats(d))\n",
        "        df = pd.DataFrame(result)\n",
        "        df.columns = ['date', 'expiry_date', 'tte', 'tau', 'delta', 'IV', 'sigma', 'N_inv', 'm']\n",
        "        df = df.groupby(['date', 'm', 'tau', 'delta'])['IV'].mean().reset_index()\n",
        "        df = df[df.IV < 1]\n",
        "        return df\n",
        "\n",
        "class fitSurface:\n",
        "    \"\"\"\n",
        "    columns = ['date','m','tau','delta','IV']\n",
        "    fit a surface to the IV data with a discrete grid of m and tau\n",
        "    following Dumas et al. (1998)\n",
        "    \"\"\"\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "        self.grid_tau = [x/365 for x in [10,30,60,91,122,152,182,273,365,547,730]]\n",
        "        self.grid_m = [np.log(m) for m in [0.6, 0.8, 0.9, 0.95, 0.975, 1, 1.025, 1.05, 1.1, 1.2, 1.3, 1.5, 1.75, 2]]\n",
        "        try:\n",
        "            self.dates = self.df['date'].unique()\n",
        "        except:\n",
        "            raise ValueError('Input dataframe must have a \"date\" column')\n",
        "\n",
        "    def _fit_and_get_model_params(self):\n",
        "        self.df['m_squared'] = self.df['m']**2\n",
        "        self.df['tau_squared'] = self.df['tau']**2\n",
        "        self.df['m_tau'] = self.df['m'] * self.df['tau']\n",
        "        X = self.df[['m', 'tau', 'm_squared', 'tau_squared', 'm_tau']]\n",
        "        y = self.df['IV']\n",
        "        model = LinearRegression()\n",
        "        model.fit(X, y)\n",
        "        return model\n",
        "\n",
        "    def _predict(self, tau, m, model):\n",
        "        m_squared = m**2\n",
        "        tau_squared = tau**2\n",
        "        m_tau = m * tau\n",
        "        input_data = pd.DataFrame({'m': [m], 'tau': [tau], 'm_squared': [m_squared], 'tau_squared': [tau_squared], 'm_tau': [m_tau]})\n",
        "        iv_ = max(0.01, model.predict(input_data)[0])\n",
        "        return iv_\n",
        "\n",
        "    def fit(self):\n",
        "        predicted_iv = pd.DataFrame()\n",
        "        model = self._fit_and_get_model_params()\n",
        "        for date in self.dates:\n",
        "            for tau in self.grid_tau:\n",
        "                for m in self.grid_m:\n",
        "                    iv = self._predict(tau, m, model)\n",
        "                    new_row = pd.DataFrame({'date': [date], 'tau': [tau], 'm': [m], 'IV': [iv]})\n",
        "                    predicted_iv = pd.concat([predicted_iv, new_row])\n",
        "\n",
        "        predicted_iv.columns = ['date', 'tau', 'm', 'IV']\n",
        "        return predicted_iv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "vmjFh6Ho7s5D",
        "outputId": "f31bdce2-7286-490a-a6e8-aee88db9de59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-05-06 15:18:59\n",
            "No data found\n",
            "{'endpoint': 'Historical Options', 'message': 'No data for symbol SPY on date 2016-01-01. Please specify a valid combination of symbol and trading day.', 'data': []}\n",
            "No data found\n",
            "{'endpoint': 'Historical Options', 'message': 'No data for symbol SPY on date 2016-01-02. Please specify a valid combination of symbol and trading day.', 'data': []}\n",
            "No data found\n",
            "{'endpoint': 'Historical Options', 'message': 'No data for symbol SPY on date 2016-01-03. Please specify a valid combination of symbol and trading day.', 'data': []}\n"
          ]
        },
        {
          "ename": "JSONDecodeError",
          "evalue": "Expecting value: line 1 column 1 (char 0)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mjson\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    973\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcomplexjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    975\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mJSONDecodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/simplejson/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, use_decimal, allow_nan, **kw)\u001b[0m\n\u001b[1;32m    513\u001b[0m             and not use_decimal and not allow_nan and not kw):\n\u001b[0;32m--> 514\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/simplejson/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w, _PY3)\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/simplejson/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx, _w, _PY3)\u001b[0m\n\u001b[1;32m    415\u001b[0m                 \u001b[0midx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-da61e5ad3feb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2016-01-01'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2016-12-31'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'spy_options_data_20.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# preprocess = preprocessData('./spy_options_data_23.json')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#df = preprocess.fit()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#print(df.head())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-ff0a53f13783>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, start_date, end_date, savefile)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msavefile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mcwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0msavefile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msavefile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-ff0a53f13783>\u001b[0m in \u001b[0;36m_fetch_data\u001b[0;34m(self, start_date, end_date)\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'https://www.alphavantage.co/query?function=HISTORICAL_OPTIONS&symbol={self.symbol}&date={query_date_str}&apikey={current_key}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'message'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'success'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mjson\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;31m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m             \u001b[0;31m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRequestsJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
          ]
        }
      ],
      "source": [
        "# get = getData()\n",
        "# get.run('2016-01-01', '2016-12-31', 'spy_options_data_20.json')\n",
        "preprocess = preprocessData('./spy_options_data_23.json')\n",
        "df = preprocess.fit()\n",
        "print(df.head())\n",
        "fit = fitSurface(df)\n",
        "predicted_iv = fit.fit()\n",
        "print(predicted_iv)\n",
        "predicted_iv.to_csv('./predicted_iv_23q1.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKNoMw1TK43d"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env1",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
