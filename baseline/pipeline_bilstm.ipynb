{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bi-LSTM for Feature Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.bilstm import BiLSTMDatasetManager, BiLSTMModelManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/processed/features_pca_iv16-20.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BiLSTMDatasetManager(data_path)\n",
    "features, targets = dataset.make_train_target_pairs()\n",
    "print('Features shape:', features.shape)\n",
    "print('Targets shape:', targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Initializing BiLSTM model...')\n",
    "model_path = './ckpts/test_bilstm256.pth'\n",
    "model = BiLSTMModelManager(input_dim=9, hidden_dim=256, output_dim=3, learning_rate=0.01, model_path=model_path)\n",
    "model.train(features, targets, epochs=250000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from models.bilstm import CustomBiLSTMModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42272/4007657262.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  bilstm_model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = './ckpts/test_bilstm256.pth'\n",
    "bilstm_model = CustomBiLSTMModel(input_dim=9, hidden_dim=256, output_dim=3)\n",
    "bilstm_model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>-2.946036</td>\n",
       "      <td>0.399305</td>\n",
       "      <td>2.333101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>-2.890993</td>\n",
       "      <td>0.153763</td>\n",
       "      <td>2.388737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>-4.476846</td>\n",
       "      <td>2.506460</td>\n",
       "      <td>2.701483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-08</td>\n",
       "      <td>-3.925725</td>\n",
       "      <td>1.810529</td>\n",
       "      <td>2.540009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-11</td>\n",
       "      <td>-4.277851</td>\n",
       "      <td>2.453446</td>\n",
       "      <td>2.562114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  feature1  feature2  feature3\n",
       "0  2016-01-05 -2.946036  0.399305  2.333101\n",
       "1  2016-01-06 -2.890993  0.153763  2.388737\n",
       "2  2016-01-07 -4.476846  2.506460  2.701483\n",
       "3  2016-01-08 -3.925725  1.810529  2.540009\n",
       "4  2016-01-11 -4.277851  2.453446  2.562114"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.read_csv(\"../data/processed/features_pca_iv16-20.csv\")\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(22,len(features)):\n",
    "    ma1 = torch.tensor(features.iloc[i-1][['feature1', 'feature2', 'feature3']].astype(float).values, dtype=torch.float32)\n",
    "    ma5 = torch.tensor(features.iloc[i-5:i][['feature1', 'feature2', 'feature3']].mean(axis=0).values, dtype=torch.float32)\n",
    "    ma22 = torch.tensor(features.iloc[i-22:i][['feature1', 'feature2', 'feature3']].mean(axis=0).values, dtype=torch.float32)\n",
    "    feature = torch.cat((ma1, ma5, ma22), dim=0).to(device)\n",
    "    out = bilstm_model.predict(feature)\n",
    "    for obj in out:\n",
    "        features.at[i, \"F1\"] = obj[0].item()\n",
    "        features.at[i, \"F2\"] = obj[1].item()\n",
    "        features.at[i, \"F3\"] = obj[2].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-02-05</td>\n",
       "      <td>-2.785850</td>\n",
       "      <td>0.208685</td>\n",
       "      <td>2.273442</td>\n",
       "      <td>-2.866897</td>\n",
       "      <td>0.122800</td>\n",
       "      <td>2.436066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-02-08</td>\n",
       "      <td>-2.426245</td>\n",
       "      <td>-0.018148</td>\n",
       "      <td>2.072642</td>\n",
       "      <td>-2.711939</td>\n",
       "      <td>0.211495</td>\n",
       "      <td>2.214754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-02-09</td>\n",
       "      <td>-2.978782</td>\n",
       "      <td>0.438694</td>\n",
       "      <td>2.333295</td>\n",
       "      <td>-3.057659</td>\n",
       "      <td>0.473622</td>\n",
       "      <td>2.400317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-02-10</td>\n",
       "      <td>-3.273419</td>\n",
       "      <td>0.806418</td>\n",
       "      <td>2.418158</td>\n",
       "      <td>-3.468703</td>\n",
       "      <td>1.069636</td>\n",
       "      <td>2.478444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-02-11</td>\n",
       "      <td>-2.607269</td>\n",
       "      <td>0.123359</td>\n",
       "      <td>2.159899</td>\n",
       "      <td>-2.746451</td>\n",
       "      <td>0.177474</td>\n",
       "      <td>2.305250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  feature1  feature2  feature3        F1        F2        F3\n",
       "0  2016-02-05 -2.785850  0.208685  2.273442 -2.866897  0.122800  2.436066\n",
       "1  2016-02-08 -2.426245 -0.018148  2.072642 -2.711939  0.211495  2.214754\n",
       "2  2016-02-09 -2.978782  0.438694  2.333295 -3.057659  0.473622  2.400317\n",
       "3  2016-02-10 -3.273419  0.806418  2.418158 -3.468703  1.069636  2.478444\n",
       "4  2016-02-11 -2.607269  0.123359  2.159899 -2.746451  0.177474  2.305250"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = features.dropna().reset_index(drop=True)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iv_path_list = [\n",
    "    \"../data/processed/pca/predicted_iv16.csv\",\n",
    "    \"../data/processed/pca/predicted_iv17.csv\",\n",
    "    \"../data/processed/pca/predicted_iv18.csv\",\n",
    "    \"../data/processed/pca/predicted_iv19.csv\",\n",
    "    \"../data/processed/pca/predicted_iv20.csv\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193424\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tau</th>\n",
       "      <th>m</th>\n",
       "      <th>IV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>0.326153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>-0.223144</td>\n",
       "      <td>0.291228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>-0.105361</td>\n",
       "      <td>0.286565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>-0.051293</td>\n",
       "      <td>0.286299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>-0.025318</td>\n",
       "      <td>0.286591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date       tau         m        IV\n",
       "0  2016-01-04  0.027397 -0.510826  0.326153\n",
       "1  2016-01-04  0.027397 -0.223144  0.291228\n",
       "2  2016-01-04  0.027397 -0.105361  0.286565\n",
       "3  2016-01-04  0.027397 -0.051293  0.286299\n",
       "4  2016-01-04  0.027397 -0.025318  0.286591"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.DataFrame()\n",
    "for path in df_iv_path_list:\n",
    "    df = pd.read_csv(path)\n",
    "    merged_df = pd.concat([merged_df, df], axis=0)\n",
    "\n",
    "merged_df = merged_df.reset_index(drop=True)\n",
    "print(len(merged_df))\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tau</th>\n",
       "      <th>m</th>\n",
       "      <th>IV</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-02-05</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>0.346719</td>\n",
       "      <td>-2.78585</td>\n",
       "      <td>0.208685</td>\n",
       "      <td>2.273442</td>\n",
       "      <td>-2.866897</td>\n",
       "      <td>0.1228</td>\n",
       "      <td>2.436066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-02-05</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>-0.223144</td>\n",
       "      <td>0.309534</td>\n",
       "      <td>-2.78585</td>\n",
       "      <td>0.208685</td>\n",
       "      <td>2.273442</td>\n",
       "      <td>-2.866897</td>\n",
       "      <td>0.1228</td>\n",
       "      <td>2.436066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-02-05</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>-0.105361</td>\n",
       "      <td>0.304773</td>\n",
       "      <td>-2.78585</td>\n",
       "      <td>0.208685</td>\n",
       "      <td>2.273442</td>\n",
       "      <td>-2.866897</td>\n",
       "      <td>0.1228</td>\n",
       "      <td>2.436066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-02-05</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>-0.051293</td>\n",
       "      <td>0.304623</td>\n",
       "      <td>-2.78585</td>\n",
       "      <td>0.208685</td>\n",
       "      <td>2.273442</td>\n",
       "      <td>-2.866897</td>\n",
       "      <td>0.1228</td>\n",
       "      <td>2.436066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-02-05</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>-0.025318</td>\n",
       "      <td>0.305006</td>\n",
       "      <td>-2.78585</td>\n",
       "      <td>0.208685</td>\n",
       "      <td>2.273442</td>\n",
       "      <td>-2.866897</td>\n",
       "      <td>0.1228</td>\n",
       "      <td>2.436066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date       tau         m        IV  feature1  feature2  feature3  \\\n",
       "0  2016-02-05  0.027397 -0.510826  0.346719  -2.78585  0.208685  2.273442   \n",
       "1  2016-02-05  0.027397 -0.223144  0.309534  -2.78585  0.208685  2.273442   \n",
       "2  2016-02-05  0.027397 -0.105361  0.304773  -2.78585  0.208685  2.273442   \n",
       "3  2016-02-05  0.027397 -0.051293  0.304623  -2.78585  0.208685  2.273442   \n",
       "4  2016-02-05  0.027397 -0.025318  0.305006  -2.78585  0.208685  2.273442   \n",
       "\n",
       "         F1      F2        F3  \n",
       "0 -2.866897  0.1228  2.436066  \n",
       "1 -2.866897  0.1228  2.436066  \n",
       "2 -2.866897  0.1228  2.436066  \n",
       "3 -2.866897  0.1228  2.436066  \n",
       "4 -2.866897  0.1228  2.436066  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join the two dataframes using the date column so that we have the corresponding F1, F2, F3 values for each date\n",
    "df = pd.merge(merged_df, features, on='date')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189882"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[:10000]\n",
    "df_val = df[-2000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['F1', 'F2', 'F3']\n",
    "from models.dnn import IVDataset, IVSDNN, train_model, large_moneyness_penalty, butterfly_arbitrage_penalty, calendar_spread_penalty, safe_divide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tensor shapes:\n",
      "Features: torch.Size([10000, 3])\n",
      "m: torch.Size([10000, 1])\n",
      "tau: torch.Size([10000, 1])\n",
      "iv: torch.Size([10000, 1])\n",
      "\n",
      "Checking for NaN values:\n",
      "Features NaN: False\n",
      "m NaN: False\n",
      "tau NaN: False\n",
      "iv NaN: False\n",
      "\n",
      "Tensor shapes:\n",
      "Features: torch.Size([2000, 3])\n",
      "m: torch.Size([2000, 1])\n",
      "tau: torch.Size([2000, 1])\n",
      "iv: torch.Size([2000, 1])\n",
      "\n",
      "Checking for NaN values:\n",
      "Features NaN: False\n",
      "m NaN: False\n",
      "tau NaN: False\n",
      "iv NaN: False\n"
     ]
    }
   ],
   "source": [
    "dataset_train = IVDataset(df_train, feature_cols)\n",
    "dataset_val = IVDataset(df_val, feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(dataset_train.get_input_size())\n",
    "print(dataset_val.get_input_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(dataset_train, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(dataset_val, batch_size=64, shuffle=False)\n",
    "dnn = IVSDNN(input_size=dataset_train.get_input_size(), hidden_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mabhigyanshanker\u001b[0m (\u001b[33mabx-group\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/shankerabhigyan/code/thesis/thesis-IVS/baseline/wandb/run-20250219_105840-8fssmzli</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/abx-group/ivs-dnn/runs/8fssmzli' target=\"_blank\">graceful-armadillo-88</a></strong> to <a href='https://wandb.ai/abx-group/ivs-dnn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/abx-group/ivs-dnn' target=\"_blank\">https://wandb.ai/abx-group/ivs-dnn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/abx-group/ivs-dnn/runs/8fssmzli' target=\"_blank\">https://wandb.ai/abx-group/ivs-dnn/runs/8fssmzli</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shankerabhigyan/miniconda3/envs/torch/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Epoch 1/200 - Training: 100%|██████████| 157/157 [08:50<00:00,  3.38s/it]\n",
      "Epoch 1/200 - Validation: 100%|██████████| 32/32 [00:34<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 Results:\n",
      "Training || Loss: 5467199.631508 | MSE: 0.063333 | MAPE: 99.532249 | Penalty: 27335995.961902\n",
      "Validation || Loss: 0.431532 | MSE: 0.078837 | MAPE: 99.999380 | Penalty: 0.000000\n",
      "Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/200 - Training: 100%|██████████| 157/157 [08:41<00:00,  3.32s/it]\n",
      "Epoch 2/200 - Validation: 100%|██████████| 32/32 [00:33<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 Results:\n",
      "Training || Loss: 0.423771 | MSE: 0.059184 | MAPE: 99.995059 | Penalty: 0.000585\n",
      "Validation || Loss: 0.439814 | MSE: 0.078821 | MAPE: 99.984962 | Penalty: 0.041727\n",
      "Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/200 - Training: 100%|██████████| 157/157 [08:44<00:00,  3.34s/it]\n",
      "Epoch 3/200 - Validation: 100%|██████████| 32/32 [00:34<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 Results:\n",
      "Training || Loss: 0.263448 | MSE: 0.034971 | MAPE: 59.735072 | Penalty: 0.052597\n",
      "Validation || Loss: 0.547008 | MSE: 0.078564 | MAPE: 99.804328 | Penalty: 0.581826\n",
      "Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/200 - Training: 100%|██████████| 157/157 [08:45<00:00,  3.35s/it]\n",
      "Epoch 4/200 - Validation: 100%|██████████| 32/32 [00:35<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4 Results:\n",
      "Training || Loss: 0.134098 | MSE: 0.012658 | MAPE: 31.612752 | Penalty: 0.012916\n",
      "Validation || Loss: 0.491882 | MSE: 0.078832 | MAPE: 99.995416 | Penalty: 0.301835\n",
      "Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/200 - Training: 100%|██████████| 157/157 [08:43<00:00,  3.33s/it]\n",
      "Epoch 5/200 - Validation: 100%|██████████| 32/32 [00:32<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5 Results:\n",
      "Training || Loss: 0.115206 | MSE: 0.010236 | MAPE: 27.339693 | Penalty: 0.008765\n",
      "Validation || Loss: 1.505898 | MSE: 0.078664 | MAPE: 99.797431 | Penalty: 5.376211\n",
      "Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/200 - Training: 100%|██████████| 157/157 [08:19<00:00,  3.18s/it]\n",
      "Epoch 6/200 - Validation: 100%|██████████| 32/32 [00:31<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6 Results:\n",
      "Training || Loss: 0.096580 | MSE: 0.007726 | MAPE: 23.141202 | Penalty: 0.004621\n",
      "Validation || Loss: 9.748625 | MSE: 0.038326 | MAPE: 64.748475 | Penalty: 47.371503\n",
      "Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/200 - Training: 100%|██████████| 157/157 [08:09<00:00,  3.12s/it]\n",
      "Epoch 7/200 - Validation: 100%|██████████| 32/32 [00:31<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7 Results:\n",
      "Training || Loss: 0.087317 | MSE: 0.006705 | MAPE: 21.059622 | Penalty: 0.001982\n",
      "Validation || Loss: 38.748662 | MSE: 0.082727 | MAPE: 94.767582 | Penalty: 191.682498\n",
      "Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/200 - Training: 100%|██████████| 157/157 [08:05<00:00,  3.10s/it]\n",
      "Epoch 8/200 - Validation: 100%|██████████| 32/32 [00:31<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8 Results:\n",
      "Training || Loss: 0.080935 | MSE: 0.005851 | MAPE: 19.544406 | Penalty: 0.002084\n",
      "Validation || Loss: 0.438671 | MSE: 0.078837 | MAPE: 100.000000 | Penalty: 0.035683\n",
      "Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/200 - Training: 100%|██████████| 157/157 [08:09<00:00,  3.12s/it]\n",
      "Epoch 9/200 - Validation: 100%|██████████| 32/32 [00:31<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9 Results:\n",
      "Training || Loss: 0.086328 | MSE: 0.005485 | MAPE: 18.110702 | Penalty: 0.058455\n",
      "Validation || Loss: 9.673665 | MSE: 0.107410 | MAPE: 108.317399 | Penalty: 45.987155\n",
      "Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/200 - Training: 100%|██████████| 157/157 [08:05<00:00,  3.09s/it]\n",
      "Epoch 10/200 - Validation: 100%|██████████| 32/32 [00:31<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10 Results:\n",
      "Training || Loss: 0.072571 | MSE: 0.004817 | MAPE: 17.591181 | Penalty: 0.001395\n",
      "Validation || Loss: 20.947423 | MSE: 0.078837 | MAPE: 99.999996 | Penalty: 102.579437\n",
      "Learning Rate: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/200 - Training: 100%|██████████| 157/157 [08:10<00:00,  3.13s/it]\n",
      "Epoch 11/200 - Validation: 100%|██████████| 32/32 [00:31<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11 Results:\n",
      "Training || Loss: 0.064088 | MSE: 0.004097 | MAPE: 15.574320 | Penalty: 0.000760\n",
      "Validation || Loss: 75.342328 | MSE: 0.459203 | MAPE: 152.053284 | Penalty: 372.752156\n",
      "Learning Rate: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/200 - Training:  92%|█████████▏| 145/157 [07:31<00:37,  3.12s/it]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Fatal error while uploading data. Some run data will not be synced, but it will still be written to disk. Use `wandb sync` at the end of the run to try uploading.\n",
      "Epoch 12/200 - Training: 100%|██████████| 157/157 [08:09<00:00,  3.12s/it]\n",
      "Epoch 12/200 - Validation: 100%|██████████| 32/32 [00:31<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12 Results:\n",
      "Training || Loss: 0.062577 | MSE: 0.003851 | MAPE: 15.211253 | Penalty: 0.000956\n",
      "Validation || Loss: 240.901704 | MSE: 0.094408 | MAPE: 103.787280 | Penalty: 1202.243944\n",
      "Learning Rate: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/200 - Training: 100%|██████████| 157/157 [08:35<00:00,  3.28s/it]\n",
      "Epoch 13/200 - Validation: 100%|██████████| 32/32 [00:33<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13 Results:\n",
      "Training || Loss: 0.062981 | MSE: 0.003825 | MAPE: 15.334997 | Penalty: 0.000557\n",
      "Validation || Loss: 328.187800 | MSE: 0.078837 | MAPE: 100.000000 | Penalty: 1638.781304\n",
      "Learning Rate: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/200 - Training: 100%|██████████| 157/157 [08:36<00:00,  3.29s/it]\n",
      "Epoch 14/200 - Validation: 100%|██████████| 32/32 [00:33<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14 Results:\n",
      "Training || Loss: 0.061112 | MSE: 0.003606 | MAPE: 14.874307 | Penalty: 0.000862\n",
      "Validation || Loss: 739.240942 | MSE: 0.078837 | MAPE: 100.000000 | Penalty: 3694.046949\n",
      "Learning Rate: 0.000090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/200 - Training: 100%|██████████| 157/157 [08:33<00:00,  3.27s/it]\n",
      "Epoch 15/200 - Validation: 100%|██████████| 32/32 [00:33<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15 Results:\n",
      "Training || Loss: 0.058640 | MSE: 0.003395 | MAPE: 14.291230 | Penalty: 0.000588\n",
      "Validation || Loss: 1154.604391 | MSE: 0.198981 | MAPE: 110.058356 | Penalty: 5770.422707\n",
      "Learning Rate: 0.000090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/200 - Training: 100%|██████████| 157/157 [08:35<00:00,  3.28s/it]\n",
      "Epoch 16/200 - Validation: 100%|██████████| 32/32 [00:34<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16 Results:\n",
      "Training || Loss: 0.058680 | MSE: 0.003369 | MAPE: 14.312030 | Penalty: 0.000423\n",
      "Validation || Loss: 995.923870 | MSE: 0.078837 | MAPE: 100.000000 | Penalty: 4977.461597\n",
      "Learning Rate: 0.000090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/200 - Training: 100%|██████████| 157/157 [08:36<00:00,  3.29s/it]\n",
      "Epoch 17/200 - Validation: 100%|██████████| 32/32 [00:33<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17 Results:\n",
      "Training || Loss: 0.058411 | MSE: 0.003327 | MAPE: 14.247517 | Penalty: 0.000452\n",
      "Validation || Loss: 1245.095800 | MSE: 0.078837 | MAPE: 100.000000 | Penalty: 6223.321190\n",
      "Learning Rate: 0.000090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/200 - Training:  93%|█████████▎| 146/157 [08:04<00:36,  3.32s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\n\u001b[1;32m      2\u001b[0m wandb\u001b[38;5;241m.\u001b[39minit(project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mivs-dnn\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwandb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/thesis/thesis-IVS/baseline/models/dnn.py:503\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, num_epochs, learning_rate, lambda_penalty, wandb)\u001b[0m\n\u001b[1;32m    496\u001b[0m loss \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;241m0.4\u001b[39m \u001b[38;5;241m*\u001b[39m mse \u001b[38;5;241m+\u001b[39m  \u001b[38;5;66;03m# MSE term\u001b[39;00m\n\u001b[1;32m    498\u001b[0m     \u001b[38;5;241m0.4\u001b[39m \u001b[38;5;241m*\u001b[39m (mape \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m100\u001b[39m) \u001b[38;5;241m+\u001b[39m  \u001b[38;5;66;03m# Normalized MAPE term\u001b[39;00m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;241m0.2\u001b[39m \u001b[38;5;241m*\u001b[39m total_penalty_term  \u001b[38;5;66;03m# Weighted penalty term\u001b[39;00m\n\u001b[1;32m    500\u001b[0m )\n\u001b[1;32m    502\u001b[0m \u001b[38;5;66;03m# Backward pass with gradient clipping\u001b[39;00m\n\u001b[0;32m--> 503\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    504\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m    506\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7972869b1b50>> (for post_run_cell), with arguments args (<ExecutionResult object at 7972869b3510, execution_count=16 error_before_exec=None error_in_exec= info=<ExecutionInfo object at 797293521510, raw_cell=\"import wandb\n",
      "wandb.init(project=\"ivs-dnn\")\n",
      "train_m..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/home/shankerabhigyan/code/thesis/thesis-IVS/baseline/pipeline_bilstm.ipynb#X31sZmlsZQ%3D%3D> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/wandb/sdk/wandb_init.py:446\u001b[0m, in \u001b[0;36m_WandbInit._pause_backend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    445\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpausing backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 446\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/wandb/sdk/interface/interface.py:729\u001b[0m, in \u001b[0;36mInterfaceBase.publish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    728\u001b[0m     pause \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mPauseRequest()\n\u001b[0;32m--> 729\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpause\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py:359\u001b[0m, in \u001b[0;36mInterfaceShared._publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m, pause: pb\u001b[38;5;241m.\u001b[39mPauseRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(pause\u001b[38;5;241m=\u001b[39mpause)\n\u001b[0;32m--> 359\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py:51\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_record_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py:225\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    223\u001b[0m server_req \u001b[38;5;241m=\u001b[39m spb\u001b[38;5;241m.\u001b[39mServerRequest()\n\u001b[1;32m    224\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[0;32m--> 225\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py:157\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 157\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py:154\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    152\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py:132\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    130\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 132\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"ivs-dnn\")\n",
    "train_model(dnn, train_loader, val_loader, 200, 0.001, 1, wandb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
