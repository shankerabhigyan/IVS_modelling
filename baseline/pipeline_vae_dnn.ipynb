{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_handler import preprocessData, fitSurface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\n",
    "    \"../data/processed/pca/predicted_iv16.csv\",\n",
    "    \"../data/processed/pca/predicted_iv17.csv\",\n",
    "    \"../data/processed/pca/predicted_iv18.csv\",\n",
    "    \"../data/processed/pca/predicted_iv19.csv\",\n",
    "    \"../data/processed/pca/predicted_iv20.csv\",\n",
    "    \"../data/processed/pca/predicted_iv21.csv\",\n",
    "    \"../data/processed/pca/predicted_iv22.csv\"\n",
    "]\n",
    "df = pd.concat([pd.read_csv(path) for path in paths])\n",
    "val_df = pd.read_csv(\"../data/processed/pca/predicted_iv23.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.vae_master import IVSFeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = IVSFeatureExtractor(\n",
    "        hidden_dim=4096,\n",
    "        latent_dim=16,\n",
    "        beta=1.0,\n",
    "        learning_rate=0.001\n",
    ")\n",
    "# 4096_64_1_001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = extractor.prepare_data(df)\n",
    "print(f\"Processed data shape: {processed_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor.train(processed_data, val_df, batch_size=256, n_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = extractor.extract_features(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = pd.DataFrame(features, columns=[f'feature_{i}' for i in range(features.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each date in df, append the features\n",
    "\n",
    "unique_dates = df['date'].unique()\n",
    "len(unique_dates)\n",
    "df_features['date'] = df['date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.to_csv('../data/processed/vae/features_vae_iv16_22_16.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.lstm import CustomLSTMCell, CustomLSTMModel, ModelManager, DatasetManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [f'feature_{i}' for i in range(16)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "vae_path = '../data/processed/vae/features_vae_iv16_22_16.csv'\n",
    "df = pd.read_csv(vae_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_path = '../data/processed/vae/features_vae_iv16_22_16.csv'\n",
    "dataset = DatasetManager(vae_path)\n",
    "features, targets = dataset.make_train_target_pairs(feature_cols)\n",
    "print('Features shape:', features.shape)\n",
    "print('Targets shape:', targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset into training and validation sets\n",
    "# split = int(0.8 * len(features))\n",
    "# train_features, val_features = features[:split], features[split:]\n",
    "# train_targets, val_targets = targets[:split], targets[split:]\n",
    "\n",
    "# no split\n",
    "train_features, train_targets = features, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Initializing model...')\n",
    "model_path = './ckpts/lstm_vae_1622_512.pth'\n",
    "model = ModelManager(input_dim=48, hidden_dim=512, output_dim=16, model_path=model_path, learning_rate=0.01, project='LSTM_VAE')\n",
    "model.train(train_features, train_targets, epochs=50000)\n",
    "\n",
    "#val_loader = DataLoader(TensorDataset(val_features, val_targets), batch_size=1, shuffle=False)\n",
    "#model.validate(val_loader)\n",
    "\n",
    "model.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from models.lstm import CustomLSTMCell, CustomLSTMModel, ModelManager, DatasetManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model_path = \"./ckpts/lstm_vae_1622_512.pth\"\n",
    "#lstm_model_path = './ckpts/test_bilstm256.pth'\n",
    "lstm_model = CustomLSTMModel(input_dim=48, hidden_dim=512, output_dim=16)\n",
    "lstm_model.load_model(model_path=lstm_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('../data/processed/vae/features_vae_iv16_22_16.csv')\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [f'feature_{i}' for i in range(16)]\n",
    "for i in range(22,len(features)):\n",
    "    ma1 = torch.tensor(features.iloc[i-1][feature_cols].astype(float).values, dtype=torch.float32).to(device)\n",
    "    ma2 = torch.tensor(features.iloc[i-2][feature_cols].astype(float).values, dtype=torch.float32).to(device)\n",
    "    ma3 = torch.tensor(features.iloc[i-3][feature_cols].astype(float).values, dtype=torch.float32).to(device)\n",
    "    feature = torch.cat((ma1, ma2, ma3), dim=0).to(device)\n",
    "    out = lstm_model.predict(feature)\n",
    "    for j in range(16):\n",
    "        features.at[i, f'feature_{j}'] = out[0][j].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features[22:].reset_index(drop=True)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iv_path_list = [\n",
    "    \"../data/processed/pca/predicted_iv16.csv\",\n",
    "    \"../data/processed/pca/predicted_iv17.csv\",\n",
    "    \"../data/processed/pca/predicted_iv18.csv\",\n",
    "    \"../data/processed/pca/predicted_iv19.csv\",\n",
    "    \"../data/processed/pca/predicted_iv20.csv\",\n",
    "    \"../data/processed/pca/predicted_iv21.csv\",\n",
    "    \"../data/processed/pca/predicted_iv22.csv\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.DataFrame()\n",
    "for path in df_iv_path_list:\n",
    "    df = pd.read_csv(path)\n",
    "    merged_df = pd.concat([merged_df, df], axis=0)\n",
    "\n",
    "merged_df = merged_df.reset_index(drop=True)\n",
    "print(len(merged_df))\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(merged_df, features, on='date')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[:30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.dnn import IVDataset, IVSDNN, train_model, large_moneyness_penalty, butterfly_arbitrage_penalty, calendar_spread_penalty, safe_divide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = IVDataset(df, feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.get_input_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(dataset, batch_size=256, shuffle=True)\n",
    "dnn = IVSDNN(input_size=dataset.get_input_size(), hidden_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_penalty=1\n",
    "num_epochs=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"vae-dnn\")\n",
    "train_model(dnn, train_loader, 100, 0.001, 1, wandb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_data_ranges(train_loader):\n",
    "    m_min, m_max = float('inf'), -float('inf')\n",
    "    tau_min, tau_max = float('inf'), -float('inf')\n",
    "    iv_min, iv_max = float('inf'), -float('inf')\n",
    "    \n",
    "    for batch_inputs, batch_targets in train_loader:\n",
    "        m = batch_inputs[:, -2]\n",
    "        tau = batch_inputs[:, -1]\n",
    "        \n",
    "        m_min = min(m_min, m.min().item())\n",
    "        m_max = max(m_max, m.max().item())\n",
    "        tau_min = min(tau_min, tau.min().item())\n",
    "        tau_max = max(tau_max, tau.max().item())\n",
    "        iv_min = min(iv_min, batch_targets.min().item())\n",
    "        iv_max = max(iv_max, batch_targets.max().item())\n",
    "    \n",
    "    print(f\"Data ranges:\")\n",
    "    print(f\"Moneyness: [{m_min:.3f}, {m_max:.3f}]\")\n",
    "    print(f\"Tau: [{tau_min:.3f}, {tau_max:.3f}]\")\n",
    "    print(f\"IV: [{iv_min:.3f}, {iv_max:.3f}]\")\n",
    "\n",
    "verify_data_ranges(train_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
