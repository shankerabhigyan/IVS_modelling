{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_handler import preprocessData, fitSurface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\n",
    "    \"../data/processed/pca/predicted_iv16.csv\",\n",
    "    \"../data/processed/pca/predicted_iv17.csv\",\n",
    "    \"../data/processed/pca/predicted_iv18.csv\",\n",
    "    \"../data/processed/pca/predicted_iv19.csv\",\n",
    "    \"../data/processed/pca/predicted_iv20.csv\",\n",
    "    \"../data/processed/pca/predicted_iv21.csv\",\n",
    "    \"../data/processed/pca/predicted_iv22.csv\"\n",
    "]\n",
    "df = pd.concat([pd.read_csv(path) for path in paths])\n",
    "val_df = pd.read_csv(\"../data/processed/pca/predicted_iv23.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.vae_master import IVSFeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = IVSFeatureExtractor(\n",
    "        hidden_dim=4096,\n",
    "        latent_dim=16,\n",
    "        beta=1.0,\n",
    "        learning_rate=0.001\n",
    ")\n",
    "# 4096_64_1_001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = extractor.prepare_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor.train(processed_data, val_df, batch_size=256, n_epochs=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = extractor.extract_features(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = pd.DataFrame(features, columns=[f'feature_{i}' for i in range(features.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, df_features], axis=1)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/processed/vae/features_vae_iv16_22_16.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.lstm import CustomLSTMCell, CustomLSTMModel, ModelManager, DatasetManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [f'feature_{i}' for i in range(16)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "vae_path = '../data/processed/vae/features_vae_iv16_22_16.csv'\n",
    "df = pd.read_csv(vae_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tau</th>\n",
       "      <th>m</th>\n",
       "      <th>IV</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_12</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>0.326153</td>\n",
       "      <td>-0.028021</td>\n",
       "      <td>-0.018182</td>\n",
       "      <td>0.631262</td>\n",
       "      <td>-0.012937</td>\n",
       "      <td>0.010283</td>\n",
       "      <td>0.008706</td>\n",
       "      <td>-0.008162</td>\n",
       "      <td>0.005395</td>\n",
       "      <td>0.020689</td>\n",
       "      <td>0.025132</td>\n",
       "      <td>-0.035328</td>\n",
       "      <td>0.013297</td>\n",
       "      <td>0.292830</td>\n",
       "      <td>0.051068</td>\n",
       "      <td>0.001593</td>\n",
       "      <td>-0.004782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>-0.223144</td>\n",
       "      <td>0.291228</td>\n",
       "      <td>0.094499</td>\n",
       "      <td>-0.021492</td>\n",
       "      <td>0.521984</td>\n",
       "      <td>-0.012051</td>\n",
       "      <td>0.016390</td>\n",
       "      <td>0.004015</td>\n",
       "      <td>-0.006669</td>\n",
       "      <td>0.006596</td>\n",
       "      <td>0.020506</td>\n",
       "      <td>0.025154</td>\n",
       "      <td>-0.021845</td>\n",
       "      <td>0.017183</td>\n",
       "      <td>0.205352</td>\n",
       "      <td>0.037030</td>\n",
       "      <td>0.004877</td>\n",
       "      <td>0.009910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>-0.105361</td>\n",
       "      <td>0.286565</td>\n",
       "      <td>0.293737</td>\n",
       "      <td>-0.019346</td>\n",
       "      <td>0.761039</td>\n",
       "      <td>-0.007869</td>\n",
       "      <td>0.012253</td>\n",
       "      <td>0.004778</td>\n",
       "      <td>-0.013257</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>0.025855</td>\n",
       "      <td>0.029640</td>\n",
       "      <td>-0.030230</td>\n",
       "      <td>0.015397</td>\n",
       "      <td>0.283865</td>\n",
       "      <td>0.054386</td>\n",
       "      <td>0.002579</td>\n",
       "      <td>0.005995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>-0.051293</td>\n",
       "      <td>0.286299</td>\n",
       "      <td>-0.724118</td>\n",
       "      <td>-0.007250</td>\n",
       "      <td>0.172510</td>\n",
       "      <td>-0.001183</td>\n",
       "      <td>-0.000178</td>\n",
       "      <td>0.011536</td>\n",
       "      <td>0.002503</td>\n",
       "      <td>-0.006915</td>\n",
       "      <td>0.006890</td>\n",
       "      <td>0.017489</td>\n",
       "      <td>-0.017773</td>\n",
       "      <td>-0.002999</td>\n",
       "      <td>0.492829</td>\n",
       "      <td>0.019699</td>\n",
       "      <td>0.013059</td>\n",
       "      <td>-0.005291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>-0.025318</td>\n",
       "      <td>0.286591</td>\n",
       "      <td>-0.568138</td>\n",
       "      <td>-0.008606</td>\n",
       "      <td>0.297375</td>\n",
       "      <td>-0.004034</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.005638</td>\n",
       "      <td>-0.004817</td>\n",
       "      <td>-0.005480</td>\n",
       "      <td>0.009535</td>\n",
       "      <td>0.021787</td>\n",
       "      <td>-0.019562</td>\n",
       "      <td>-0.002383</td>\n",
       "      <td>0.628638</td>\n",
       "      <td>0.029114</td>\n",
       "      <td>0.017934</td>\n",
       "      <td>-0.001628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date       tau         m        IV  feature_0  feature_1  feature_2  \\\n",
       "0  2016-01-04  0.027397 -0.510826  0.326153  -0.028021  -0.018182   0.631262   \n",
       "1  2016-01-04  0.027397 -0.223144  0.291228   0.094499  -0.021492   0.521984   \n",
       "2  2016-01-04  0.027397 -0.105361  0.286565   0.293737  -0.019346   0.761039   \n",
       "3  2016-01-04  0.027397 -0.051293  0.286299  -0.724118  -0.007250   0.172510   \n",
       "4  2016-01-04  0.027397 -0.025318  0.286591  -0.568138  -0.008606   0.297375   \n",
       "\n",
       "   feature_3  feature_4  feature_5  feature_6  feature_7  feature_8  \\\n",
       "0  -0.012937   0.010283   0.008706  -0.008162   0.005395   0.020689   \n",
       "1  -0.012051   0.016390   0.004015  -0.006669   0.006596   0.020506   \n",
       "2  -0.007869   0.012253   0.004778  -0.013257   0.006969   0.025855   \n",
       "3  -0.001183  -0.000178   0.011536   0.002503  -0.006915   0.006890   \n",
       "4  -0.004034   0.000377   0.005638  -0.004817  -0.005480   0.009535   \n",
       "\n",
       "   feature_9  feature_10  feature_11  feature_12  feature_13  feature_14  \\\n",
       "0   0.025132   -0.035328    0.013297    0.292830    0.051068    0.001593   \n",
       "1   0.025154   -0.021845    0.017183    0.205352    0.037030    0.004877   \n",
       "2   0.029640   -0.030230    0.015397    0.283865    0.054386    0.002579   \n",
       "3   0.017489   -0.017773   -0.002999    0.492829    0.019699    0.013059   \n",
       "4   0.021787   -0.019562   -0.002383    0.628638    0.029114    0.017934   \n",
       "\n",
       "   feature_15  \n",
       "0   -0.004782  \n",
       "1    0.009910  \n",
       "2    0.005995  \n",
       "3   -0.005291  \n",
       "4   -0.001628  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: torch.Size([270864, 48])\n",
      "Targets shape: torch.Size([270864, 16])\n"
     ]
    }
   ],
   "source": [
    "vae_path = '../data/processed/vae/features_vae_iv16_22_16.csv'\n",
    "dataset = DatasetManager(vae_path)\n",
    "features, targets = dataset.make_train_target_pairs(feature_cols)\n",
    "print('Features shape:', features.shape)\n",
    "print('Targets shape:', targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset into training and validation sets\n",
    "# split = int(0.8 * len(features))\n",
    "# train_features, val_features = features[:split], features[split:]\n",
    "# train_targets, val_targets = targets[:split], targets[split:]\n",
    "\n",
    "# no split\n",
    "train_features, train_targets = features, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mabhigyanshanker\u001b[0m (\u001b[33mabx-group\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/shankerabhigyan/code/thesis/thesis-IVS/baseline/wandb/run-20241113_114859-fdgiarp9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/abx-group/IVS_LSTM/runs/fdgiarp9' target=\"_blank\">blooming-snow-21</a></strong> to <a href='https://wandb.ai/abx-group/IVS_LSTM' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/abx-group/IVS_LSTM' target=\"_blank\">https://wandb.ai/abx-group/IVS_LSTM</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/abx-group/IVS_LSTM/runs/fdgiarp9' target=\"_blank\">https://wandb.ai/abx-group/IVS_LSTM/runs/fdgiarp9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: nan MAPE: nan\n",
      "Epoch 2 Loss: nan MAPE: nan\n",
      "Epoch 3 Loss: nan MAPE: nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./ckpts/lstm_vae_1620_1024.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m ModelManager(input_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m192\u001b[39m, hidden_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m, output_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, model_path\u001b[38;5;241m=\u001b[39mmodel_path, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#val_loader = DataLoader(TensorDataset(val_features, val_targets), batch_size=1, shuffle=False)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#model.validate(val_loader)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39msave_model()\n",
      "File \u001b[0;32m~/code/thesis/thesis-IVS/baseline/models/lstm.py:91\u001b[0m, in \u001b[0;36mModelManager.train\u001b[0;34m(self, train_data, train_targets, batch_size, epochs, val_data, val_labels)\u001b[0m\n\u001b[1;32m     89\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     90\u001b[0m running_mape \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 91\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Zero the parameter gradients\u001b[39;49;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/torch/utils/data/dataset.py:211\u001b[0m, in \u001b[0;36mTensorDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(tensor[index] \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/torch/utils/data/dataset.py:211\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(tensor[index] \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('Initializing model...')\n",
    "model_path = './ckpts/lstm_vae_1620_1024.pth'\n",
    "model = ModelManager(input_dim=192, hidden_dim=1024, output_dim=64, model_path=model_path, learning_rate=0.01)\n",
    "model.train(train_features, train_targets, epochs=200000)\n",
    "\n",
    "#val_loader = DataLoader(TensorDataset(val_features, val_targets), batch_size=1, shuffle=False)\n",
    "#model.validate(val_loader)\n",
    "\n",
    "model.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random feature-sample pair:\n",
      "Feature: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Target: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])\n"
     ]
    }
   ],
   "source": [
    "# print random feature-sample pair\n",
    "print('Random feature-sample pair:')\n",
    "idx = np.random.randint(0, len(train_features))\n",
    "print('Feature:', train_features[idx])\n",
    "print('Target:', train_targets[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
