{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_handler import preprocessData, fitSurface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\n",
    "    \"../data/processed/pca/predicted_iv16.csv\",\n",
    "    \"../data/processed/pca/predicted_iv17.csv\",\n",
    "    \"../data/processed/pca/predicted_iv18.csv\",\n",
    "    \"../data/processed/pca/predicted_iv19.csv\",\n",
    "    \"../data/processed/pca/predicted_iv20.csv\",\n",
    "    \"../data/processed/pca/predicted_iv21.csv\",\n",
    "    \"../data/processed/pca/predicted_iv22.csv\"\n",
    "]\n",
    "df = pd.concat([pd.read_csv(path) for path in paths])\n",
    "val_df = pd.read_csv(\"../data/processed/pca/predicted_iv23.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.vae_master import IVSFeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = IVSFeatureExtractor(\n",
    "        hidden_dim=4096,\n",
    "        latent_dim=16,\n",
    "        beta=1.0,\n",
    "        learning_rate=0.001\n",
    ")\n",
    "# 4096_64_1_001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = extractor.prepare_data(df)\n",
    "print(f\"Processed data shape: {processed_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor.train(processed_data, val_df, batch_size=256, n_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = extractor.extract_features(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = pd.DataFrame(features, columns=[f'feature_{i}' for i in range(features.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each date in df, append the features\n",
    "\n",
    "unique_dates = df['date'].unique()\n",
    "len(unique_dates)\n",
    "df_features['date'] = df['date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.to_csv('../data/processed/vae/features_vae_iv16_22_16.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.lstm import CustomLSTMCell, CustomLSTMModel, ModelManager, DatasetManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [f'feature_{i}' for i in range(16)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "vae_path = '../data/processed/vae/features_vae_iv16_22_16.csv'\n",
    "df = pd.read_csv(vae_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_path = '../data/processed/vae/features_vae_iv16_22_16.csv'\n",
    "dataset = DatasetManager(vae_path)\n",
    "features, targets = dataset.make_train_target_pairs(feature_cols)\n",
    "print('Features shape:', features.shape)\n",
    "print('Targets shape:', targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset into training and validation sets\n",
    "# split = int(0.8 * len(features))\n",
    "# train_features, val_features = features[:split], features[split:]\n",
    "# train_targets, val_targets = targets[:split], targets[split:]\n",
    "\n",
    "# no split\n",
    "train_features, train_targets = features, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Initializing model...')\n",
    "model_path = './ckpts/lstm_vae_1622_512.pth'\n",
    "model = ModelManager(input_dim=48, hidden_dim=512, output_dim=16, model_path=model_path, learning_rate=0.01, project='LSTM_VAE')\n",
    "model.train(train_features, train_targets, epochs=50000)\n",
    "\n",
    "#val_loader = DataLoader(TensorDataset(val_features, val_targets), batch_size=1, shuffle=False)\n",
    "#model.validate(val_loader)\n",
    "\n",
    "model.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from models.lstm import CustomLSTMCell, CustomLSTMModel, ModelManager, DatasetManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from ./ckpts/lstm_vae_1622_512.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shankerabhigyan/code/thesis/thesis-IVS/baseline/models/lstm.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.load_state_dict(torch.load(model_path))\n"
     ]
    }
   ],
   "source": [
    "lstm_model_path = \"./ckpts/lstm_vae_1622_512.pth\"\n",
    "#lstm_model_path = './ckpts/test_bilstm256.pth'\n",
    "lstm_model = CustomLSTMModel(input_dim=48, hidden_dim=512, output_dim=16)\n",
    "lstm_model.load_model(model_path=lstm_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_12</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.013490</td>\n",
       "      <td>0.016726</td>\n",
       "      <td>0.001015</td>\n",
       "      <td>0.006635</td>\n",
       "      <td>0.355671</td>\n",
       "      <td>0.268430</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>-0.002008</td>\n",
       "      <td>-0.017450</td>\n",
       "      <td>0.014705</td>\n",
       "      <td>-0.000923</td>\n",
       "      <td>0.006342</td>\n",
       "      <td>0.012619</td>\n",
       "      <td>-0.003463</td>\n",
       "      <td>-0.007455</td>\n",
       "      <td>0.001140</td>\n",
       "      <td>2016-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.016278</td>\n",
       "      <td>0.016848</td>\n",
       "      <td>0.011750</td>\n",
       "      <td>0.016990</td>\n",
       "      <td>0.366535</td>\n",
       "      <td>0.197472</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>-0.000559</td>\n",
       "      <td>-0.015649</td>\n",
       "      <td>0.017074</td>\n",
       "      <td>0.003308</td>\n",
       "      <td>0.009717</td>\n",
       "      <td>-0.080449</td>\n",
       "      <td>-0.001823</td>\n",
       "      <td>-0.003148</td>\n",
       "      <td>-0.004420</td>\n",
       "      <td>2016-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.022743</td>\n",
       "      <td>0.018066</td>\n",
       "      <td>0.015866</td>\n",
       "      <td>0.019294</td>\n",
       "      <td>0.463473</td>\n",
       "      <td>0.262002</td>\n",
       "      <td>-0.003702</td>\n",
       "      <td>0.005221</td>\n",
       "      <td>-0.015472</td>\n",
       "      <td>0.018113</td>\n",
       "      <td>-0.003555</td>\n",
       "      <td>0.007367</td>\n",
       "      <td>-0.235385</td>\n",
       "      <td>-0.001429</td>\n",
       "      <td>-0.010315</td>\n",
       "      <td>-0.002500</td>\n",
       "      <td>2016-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.002543</td>\n",
       "      <td>0.029971</td>\n",
       "      <td>-0.040378</td>\n",
       "      <td>-0.018382</td>\n",
       "      <td>0.127714</td>\n",
       "      <td>0.492194</td>\n",
       "      <td>0.015958</td>\n",
       "      <td>-0.003395</td>\n",
       "      <td>0.023379</td>\n",
       "      <td>0.037760</td>\n",
       "      <td>-0.003421</td>\n",
       "      <td>-0.008119</td>\n",
       "      <td>0.672027</td>\n",
       "      <td>0.011833</td>\n",
       "      <td>0.008432</td>\n",
       "      <td>-0.028344</td>\n",
       "      <td>2016-01-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001311</td>\n",
       "      <td>0.026650</td>\n",
       "      <td>-0.023601</td>\n",
       "      <td>-0.021134</td>\n",
       "      <td>0.192549</td>\n",
       "      <td>0.603569</td>\n",
       "      <td>0.004920</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.019321</td>\n",
       "      <td>0.034228</td>\n",
       "      <td>-0.003840</td>\n",
       "      <td>-0.013453</td>\n",
       "      <td>0.603969</td>\n",
       "      <td>0.013828</td>\n",
       "      <td>-0.002908</td>\n",
       "      <td>-0.019290</td>\n",
       "      <td>2016-01-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0   0.013490   0.016726   0.001015   0.006635   0.355671   0.268430   \n",
       "1   0.016278   0.016848   0.011750   0.016990   0.366535   0.197472   \n",
       "2   0.022743   0.018066   0.015866   0.019294   0.463473   0.262002   \n",
       "3  -0.002543   0.029971  -0.040378  -0.018382   0.127714   0.492194   \n",
       "4   0.001311   0.026650  -0.023601  -0.021134   0.192549   0.603569   \n",
       "\n",
       "   feature_6  feature_7  feature_8  feature_9  feature_10  feature_11  \\\n",
       "0   0.000592  -0.002008  -0.017450   0.014705   -0.000923    0.006342   \n",
       "1   0.000607  -0.000559  -0.015649   0.017074    0.003308    0.009717   \n",
       "2  -0.003702   0.005221  -0.015472   0.018113   -0.003555    0.007367   \n",
       "3   0.015958  -0.003395   0.023379   0.037760   -0.003421   -0.008119   \n",
       "4   0.004920   0.000244   0.019321   0.034228   -0.003840   -0.013453   \n",
       "\n",
       "   feature_12  feature_13  feature_14  feature_15        date  \n",
       "0    0.012619   -0.003463   -0.007455    0.001140  2016-01-04  \n",
       "1   -0.080449   -0.001823   -0.003148   -0.004420  2016-01-05  \n",
       "2   -0.235385   -0.001429   -0.010315   -0.002500  2016-01-06  \n",
       "3    0.672027    0.011833    0.008432   -0.028344  2016-01-07  \n",
       "4    0.603969    0.013828   -0.002908   -0.019290  2016-01-08  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.read_csv('../data/processed/vae/features_vae_iv16_22_16.csv')\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [f'feature_{i}' for i in range(16)]\n",
    "for i in range(22,len(features)):\n",
    "    ma1 = torch.tensor(features.iloc[i-1][feature_cols].astype(float).values, dtype=torch.float32).to(device)\n",
    "    ma2 = torch.tensor(features.iloc[i-2][feature_cols].astype(float).values, dtype=torch.float32).to(device)\n",
    "    ma3 = torch.tensor(features.iloc[i-3][feature_cols].astype(float).values, dtype=torch.float32).to(device)\n",
    "    feature = torch.cat((ma1, ma2, ma3), dim=0).to(device)\n",
    "    out = lstm_model.predict(feature)\n",
    "    for j in range(16):\n",
    "        features.at[i, f'feature_{j}'] = out[0][j].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_12</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.008144</td>\n",
       "      <td>-0.004826</td>\n",
       "      <td>0.000819</td>\n",
       "      <td>-0.013507</td>\n",
       "      <td>0.615582</td>\n",
       "      <td>0.646299</td>\n",
       "      <td>0.006843</td>\n",
       "      <td>0.053013</td>\n",
       "      <td>-0.001125</td>\n",
       "      <td>0.027941</td>\n",
       "      <td>-0.031726</td>\n",
       "      <td>-0.032570</td>\n",
       "      <td>0.376320</td>\n",
       "      <td>0.027101</td>\n",
       "      <td>0.008045</td>\n",
       "      <td>0.028158</td>\n",
       "      <td>2016-02-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.030909</td>\n",
       "      <td>-0.083262</td>\n",
       "      <td>-0.090908</td>\n",
       "      <td>-0.090189</td>\n",
       "      <td>0.114601</td>\n",
       "      <td>1.687865</td>\n",
       "      <td>0.115730</td>\n",
       "      <td>0.030573</td>\n",
       "      <td>-0.022653</td>\n",
       "      <td>0.055866</td>\n",
       "      <td>-0.122147</td>\n",
       "      <td>0.042756</td>\n",
       "      <td>1.085049</td>\n",
       "      <td>-0.040849</td>\n",
       "      <td>0.012105</td>\n",
       "      <td>0.042296</td>\n",
       "      <td>2016-02-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.518011</td>\n",
       "      <td>-1.111243</td>\n",
       "      <td>-1.099482</td>\n",
       "      <td>-0.402830</td>\n",
       "      <td>-0.398200</td>\n",
       "      <td>8.175017</td>\n",
       "      <td>-0.050984</td>\n",
       "      <td>0.450560</td>\n",
       "      <td>-0.083833</td>\n",
       "      <td>0.556023</td>\n",
       "      <td>-0.937338</td>\n",
       "      <td>-0.606066</td>\n",
       "      <td>6.774503</td>\n",
       "      <td>0.271807</td>\n",
       "      <td>-0.161398</td>\n",
       "      <td>1.075073</td>\n",
       "      <td>2016-02-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-15.487729</td>\n",
       "      <td>-19.178459</td>\n",
       "      <td>-1.488301</td>\n",
       "      <td>-23.767061</td>\n",
       "      <td>40.833786</td>\n",
       "      <td>85.244415</td>\n",
       "      <td>50.424183</td>\n",
       "      <td>-16.558826</td>\n",
       "      <td>-30.011923</td>\n",
       "      <td>7.000886</td>\n",
       "      <td>-40.644005</td>\n",
       "      <td>20.819012</td>\n",
       "      <td>28.950424</td>\n",
       "      <td>-23.403748</td>\n",
       "      <td>-9.569206</td>\n",
       "      <td>5.922505</td>\n",
       "      <td>2016-02-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.130387</td>\n",
       "      <td>-2.605597</td>\n",
       "      <td>-18.109007</td>\n",
       "      <td>21.915497</td>\n",
       "      <td>11.640251</td>\n",
       "      <td>40.706768</td>\n",
       "      <td>-5.848877</td>\n",
       "      <td>9.805226</td>\n",
       "      <td>25.235212</td>\n",
       "      <td>45.495163</td>\n",
       "      <td>-20.516996</td>\n",
       "      <td>-46.011906</td>\n",
       "      <td>10.775976</td>\n",
       "      <td>-16.367229</td>\n",
       "      <td>5.316827</td>\n",
       "      <td>-10.334608</td>\n",
       "      <td>2016-02-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0  -0.008144  -0.004826   0.000819  -0.013507   0.615582   0.646299   \n",
       "1  -0.030909  -0.083262  -0.090908  -0.090189   0.114601   1.687865   \n",
       "2  -0.518011  -1.111243  -1.099482  -0.402830  -0.398200   8.175017   \n",
       "3 -15.487729 -19.178459  -1.488301 -23.767061  40.833786  85.244415   \n",
       "4   3.130387  -2.605597 -18.109007  21.915497  11.640251  40.706768   \n",
       "\n",
       "   feature_6  feature_7  feature_8  feature_9  feature_10  feature_11  \\\n",
       "0   0.006843   0.053013  -0.001125   0.027941   -0.031726   -0.032570   \n",
       "1   0.115730   0.030573  -0.022653   0.055866   -0.122147    0.042756   \n",
       "2  -0.050984   0.450560  -0.083833   0.556023   -0.937338   -0.606066   \n",
       "3  50.424183 -16.558826 -30.011923   7.000886  -40.644005   20.819012   \n",
       "4  -5.848877   9.805226  25.235212  45.495163  -20.516996  -46.011906   \n",
       "\n",
       "   feature_12  feature_13  feature_14  feature_15        date  \n",
       "0    0.376320    0.027101    0.008045    0.028158  2016-02-04  \n",
       "1    1.085049   -0.040849    0.012105    0.042296  2016-02-05  \n",
       "2    6.774503    0.271807   -0.161398    1.075073  2016-02-08  \n",
       "3   28.950424  -23.403748   -9.569206    5.922505  2016-02-09  \n",
       "4   10.775976  -16.367229    5.316827  -10.334608  2016-02-10  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = features[22:].reset_index(drop=True)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iv_path_list = [\n",
    "    \"../data/processed/pca/predicted_iv16.csv\",\n",
    "    \"../data/processed/pca/predicted_iv17.csv\",\n",
    "    \"../data/processed/pca/predicted_iv18.csv\",\n",
    "    \"../data/processed/pca/predicted_iv19.csv\",\n",
    "    \"../data/processed/pca/predicted_iv20.csv\",\n",
    "    \"../data/processed/pca/predicted_iv21.csv\",\n",
    "    \"../data/processed/pca/predicted_iv22.csv\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270886\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tau</th>\n",
       "      <th>m</th>\n",
       "      <th>IV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>0.326153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>-0.223144</td>\n",
       "      <td>0.291228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>-0.105361</td>\n",
       "      <td>0.286565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>-0.051293</td>\n",
       "      <td>0.286299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>-0.025318</td>\n",
       "      <td>0.286591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date       tau         m        IV\n",
       "0  2016-01-04  0.027397 -0.510826  0.326153\n",
       "1  2016-01-04  0.027397 -0.223144  0.291228\n",
       "2  2016-01-04  0.027397 -0.105361  0.286565\n",
       "3  2016-01-04  0.027397 -0.051293  0.286299\n",
       "4  2016-01-04  0.027397 -0.025318  0.286591"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.DataFrame()\n",
    "for path in df_iv_path_list:\n",
    "    df = pd.read_csv(path)\n",
    "    merged_df = pd.concat([merged_df, df], axis=0)\n",
    "\n",
    "merged_df = merged_df.reset_index(drop=True)\n",
    "print(len(merged_df))\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tau</th>\n",
       "      <th>m</th>\n",
       "      <th>IV</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_12</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-02-04</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>0.391197</td>\n",
       "      <td>-0.008144</td>\n",
       "      <td>-0.004826</td>\n",
       "      <td>0.000819</td>\n",
       "      <td>-0.013507</td>\n",
       "      <td>0.615582</td>\n",
       "      <td>0.646299</td>\n",
       "      <td>0.006843</td>\n",
       "      <td>0.053013</td>\n",
       "      <td>-0.001125</td>\n",
       "      <td>0.027941</td>\n",
       "      <td>-0.031726</td>\n",
       "      <td>-0.03257</td>\n",
       "      <td>0.37632</td>\n",
       "      <td>0.027101</td>\n",
       "      <td>0.008045</td>\n",
       "      <td>0.028158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-02-04</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>-0.223144</td>\n",
       "      <td>0.329391</td>\n",
       "      <td>-0.008144</td>\n",
       "      <td>-0.004826</td>\n",
       "      <td>0.000819</td>\n",
       "      <td>-0.013507</td>\n",
       "      <td>0.615582</td>\n",
       "      <td>0.646299</td>\n",
       "      <td>0.006843</td>\n",
       "      <td>0.053013</td>\n",
       "      <td>-0.001125</td>\n",
       "      <td>0.027941</td>\n",
       "      <td>-0.031726</td>\n",
       "      <td>-0.03257</td>\n",
       "      <td>0.37632</td>\n",
       "      <td>0.027101</td>\n",
       "      <td>0.008045</td>\n",
       "      <td>0.028158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-02-04</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>-0.105361</td>\n",
       "      <td>0.312298</td>\n",
       "      <td>-0.008144</td>\n",
       "      <td>-0.004826</td>\n",
       "      <td>0.000819</td>\n",
       "      <td>-0.013507</td>\n",
       "      <td>0.615582</td>\n",
       "      <td>0.646299</td>\n",
       "      <td>0.006843</td>\n",
       "      <td>0.053013</td>\n",
       "      <td>-0.001125</td>\n",
       "      <td>0.027941</td>\n",
       "      <td>-0.031726</td>\n",
       "      <td>-0.03257</td>\n",
       "      <td>0.37632</td>\n",
       "      <td>0.027101</td>\n",
       "      <td>0.008045</td>\n",
       "      <td>0.028158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-02-04</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>-0.051293</td>\n",
       "      <td>0.306049</td>\n",
       "      <td>-0.008144</td>\n",
       "      <td>-0.004826</td>\n",
       "      <td>0.000819</td>\n",
       "      <td>-0.013507</td>\n",
       "      <td>0.615582</td>\n",
       "      <td>0.646299</td>\n",
       "      <td>0.006843</td>\n",
       "      <td>0.053013</td>\n",
       "      <td>-0.001125</td>\n",
       "      <td>0.027941</td>\n",
       "      <td>-0.031726</td>\n",
       "      <td>-0.03257</td>\n",
       "      <td>0.37632</td>\n",
       "      <td>0.027101</td>\n",
       "      <td>0.008045</td>\n",
       "      <td>0.028158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-02-04</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>-0.025318</td>\n",
       "      <td>0.303404</td>\n",
       "      <td>-0.008144</td>\n",
       "      <td>-0.004826</td>\n",
       "      <td>0.000819</td>\n",
       "      <td>-0.013507</td>\n",
       "      <td>0.615582</td>\n",
       "      <td>0.646299</td>\n",
       "      <td>0.006843</td>\n",
       "      <td>0.053013</td>\n",
       "      <td>-0.001125</td>\n",
       "      <td>0.027941</td>\n",
       "      <td>-0.031726</td>\n",
       "      <td>-0.03257</td>\n",
       "      <td>0.37632</td>\n",
       "      <td>0.027101</td>\n",
       "      <td>0.008045</td>\n",
       "      <td>0.028158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date       tau         m        IV  feature_0  feature_1  feature_2  \\\n",
       "0  2016-02-04  0.027397 -0.510826  0.391197  -0.008144  -0.004826   0.000819   \n",
       "1  2016-02-04  0.027397 -0.223144  0.329391  -0.008144  -0.004826   0.000819   \n",
       "2  2016-02-04  0.027397 -0.105361  0.312298  -0.008144  -0.004826   0.000819   \n",
       "3  2016-02-04  0.027397 -0.051293  0.306049  -0.008144  -0.004826   0.000819   \n",
       "4  2016-02-04  0.027397 -0.025318  0.303404  -0.008144  -0.004826   0.000819   \n",
       "\n",
       "   feature_3  feature_4  feature_5  feature_6  feature_7  feature_8  \\\n",
       "0  -0.013507   0.615582   0.646299   0.006843   0.053013  -0.001125   \n",
       "1  -0.013507   0.615582   0.646299   0.006843   0.053013  -0.001125   \n",
       "2  -0.013507   0.615582   0.646299   0.006843   0.053013  -0.001125   \n",
       "3  -0.013507   0.615582   0.646299   0.006843   0.053013  -0.001125   \n",
       "4  -0.013507   0.615582   0.646299   0.006843   0.053013  -0.001125   \n",
       "\n",
       "   feature_9  feature_10  feature_11  feature_12  feature_13  feature_14  \\\n",
       "0   0.027941   -0.031726    -0.03257     0.37632    0.027101    0.008045   \n",
       "1   0.027941   -0.031726    -0.03257     0.37632    0.027101    0.008045   \n",
       "2   0.027941   -0.031726    -0.03257     0.37632    0.027101    0.008045   \n",
       "3   0.027941   -0.031726    -0.03257     0.37632    0.027101    0.008045   \n",
       "4   0.027941   -0.031726    -0.03257     0.37632    0.027101    0.008045   \n",
       "\n",
       "   feature_15  \n",
       "0    0.028158  \n",
       "1    0.028158  \n",
       "2    0.028158  \n",
       "3    0.028158  \n",
       "4    0.028158  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(merged_df, features, on='date')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.dnn import IVDataset, IVSDNN, train_model, large_moneyness_penalty, butterfly_arbitrage_penalty, calendar_spread_penalty, safe_divide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tensor shapes:\n",
      "Features: torch.Size([267498, 16])\n",
      "m: torch.Size([267498, 1])\n",
      "tau: torch.Size([267498, 1])\n",
      "iv: torch.Size([267498, 1])\n",
      "\n",
      "Checking for NaN values:\n",
      "Features NaN: False\n",
      "m NaN: False\n",
      "tau NaN: False\n",
      "iv NaN: False\n"
     ]
    }
   ],
   "source": [
    "dataset = IVDataset(df, feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "print(dataset.get_input_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "dnn = IVSDNN(input_size=dataset.get_input_size(), hidden_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_penalty=1\n",
    "num_epochs=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mabhigyanshanker\u001b[0m (\u001b[33mabx-group\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/shankerabhigyan/code/thesis/thesis-IVS/baseline/wandb/run-20241113_153616-ms1kt0hg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/abx-group/ivs-dnn/runs/ms1kt0hg' target=\"_blank\">dutiful-bee-18</a></strong> to <a href='https://wandb.ai/abx-group/ivs-dnn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/abx-group/ivs-dnn' target=\"_blank\">https://wandb.ai/abx-group/ivs-dnn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/abx-group/ivs-dnn/runs/ms1kt0hg' target=\"_blank\">https://wandb.ai/abx-group/ivs-dnn/runs/ms1kt0hg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shankerabhigyan/miniconda3/envs/torch/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 || Loss = 0.313731 || Penalty = 0.248671 || Calendar Penalty = 0.315644 || Butterfly Penalty = 0.214365 || Large Moneyness Penalty = 0.713345 || MAPE = 99.901703\n",
      "Epoch 2 || Loss = 0.065056 || Penalty = 0.000011 || Calendar Penalty = 0.000026 || Butterfly Penalty = 0.000000 || Large Moneyness Penalty = 0.000000 || MAPE = 100.000000\n",
      "Epoch 3 || Loss = 0.065056 || Penalty = 0.000011 || Calendar Penalty = 0.000018 || Butterfly Penalty = 0.000000 || Large Moneyness Penalty = 0.000000 || MAPE = 100.000000\n",
      "Epoch 4 || Loss = 0.065056 || Penalty = 0.000011 || Calendar Penalty = 0.000013 || Butterfly Penalty = 0.000000 || Large Moneyness Penalty = 0.000000 || MAPE = 100.000000\n",
      "Epoch 5 || Loss = 0.065055 || Penalty = 0.000011 || Calendar Penalty = 0.000011 || Butterfly Penalty = 0.000000 || Large Moneyness Penalty = 0.000000 || MAPE = 100.000000\n",
      "Epoch 6 || Loss = 0.065055 || Penalty = 0.000011 || Calendar Penalty = 0.000011 || Butterfly Penalty = 0.000000 || Large Moneyness Penalty = 0.000000 || MAPE = 100.000000\n",
      "Epoch 7 || Loss = 0.065056 || Penalty = 0.000011 || Calendar Penalty = 0.000011 || Butterfly Penalty = 0.000000 || Large Moneyness Penalty = 0.000000 || MAPE = 100.000000\n",
      "Epoch 8 || Loss = 0.065057 || Penalty = 0.000011 || Calendar Penalty = 0.000011 || Butterfly Penalty = 0.000000 || Large Moneyness Penalty = 0.000000 || MAPE = 100.000000\n",
      "Epoch 9 || Loss = 0.065056 || Penalty = 0.000011 || Calendar Penalty = 0.000011 || Butterfly Penalty = 0.000000 || Large Moneyness Penalty = 0.000000 || MAPE = 100.000000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\n\u001b[1;32m      2\u001b[0m wandb\u001b[38;5;241m.\u001b[39minit(project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mivs-dnn\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwandb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/thesis/thesis-IVS/baseline/models/dnn.py:170\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, num_epochs, learning_rate, lambda_penalty, wandb)\u001b[0m\n\u001b[1;32m    168\u001b[0m epoch_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;241m1.0\u001b[39m, (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m5\u001b[39m)  \u001b[38;5;66;03m# Gradually increase penalty weight\u001b[39;00m\n\u001b[1;32m    169\u001b[0m cal_penalty \u001b[38;5;241m=\u001b[39m calendar_spread_penalty(model, features, m, tau)\n\u001b[0;32m--> 170\u001b[0m but_penalty \u001b[38;5;241m=\u001b[39m \u001b[43mbutterfly_arbitrage_penalty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtau\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m large_m_penalty \u001b[38;5;241m=\u001b[39m large_moneyness_penalty(model, features, m, tau)\n\u001b[1;32m    173\u001b[0m penalty \u001b[38;5;241m=\u001b[39m lambda_penalty \u001b[38;5;241m*\u001b[39m epoch_weight \u001b[38;5;241m*\u001b[39m (cal_penalty \u001b[38;5;241m+\u001b[39m but_penalty \u001b[38;5;241m+\u001b[39m large_m_penalty)\n",
      "File \u001b[0;32m~/code/thesis/thesis-IVS/baseline/models/dnn.py:102\u001b[0m, in \u001b[0;36mbutterfly_arbitrage_penalty\u001b[0;34m(model, features, m, tau, delta_m)\u001b[0m\n\u001b[1;32m    100\u001b[0m sigma_mid \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_iv(features, m, tau)\n\u001b[1;32m    101\u001b[0m sigma_plus \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_iv(features, m \u001b[38;5;241m+\u001b[39m delta_m, tau)\n\u001b[0;32m--> 102\u001b[0m sigma_minus \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_iv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdelta_m\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtau\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m d_sigma_dm \u001b[38;5;241m=\u001b[39m (sigma_plus \u001b[38;5;241m-\u001b[39m sigma_minus) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m delta_m)\n\u001b[1;32m    105\u001b[0m d2_sigma_dm2 \u001b[38;5;241m=\u001b[39m (sigma_plus \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39msigma_mid \u001b[38;5;241m+\u001b[39m sigma_minus) \u001b[38;5;241m/\u001b[39m (delta_m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/code/thesis/thesis-IVS/baseline/models/dnn.py:75\u001b[0m, in \u001b[0;36mIVSDNN.predict_iv\u001b[0;34m(self, features, m, tau)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_iv\u001b[39m(\u001b[38;5;28mself\u001b[39m, features, m, tau):\n\u001b[0;32m---> 75\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, m, tau], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet(x)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"ivs-dnn\")\n",
    "train_model(dnn, train_loader, 300, 0.001, 1, wandb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_data_ranges(train_loader):\n",
    "    m_min, m_max = float('inf'), -float('inf')\n",
    "    tau_min, tau_max = float('inf'), -float('inf')\n",
    "    iv_min, iv_max = float('inf'), -float('inf')\n",
    "    \n",
    "    for batch_inputs, batch_targets in train_loader:\n",
    "        m = batch_inputs[:, -2]\n",
    "        tau = batch_inputs[:, -1]\n",
    "        \n",
    "        m_min = min(m_min, m.min().item())\n",
    "        m_max = max(m_max, m.max().item())\n",
    "        tau_min = min(tau_min, tau.min().item())\n",
    "        tau_max = max(tau_max, tau.max().item())\n",
    "        iv_min = min(iv_min, batch_targets.min().item())\n",
    "        iv_max = max(iv_max, batch_targets.max().item())\n",
    "    \n",
    "    print(f\"Data ranges:\")\n",
    "    print(f\"Moneyness: [{m_min:.3f}, {m_max:.3f}]\")\n",
    "    print(f\"Tau: [{tau_min:.3f}, {tau_max:.3f}]\")\n",
    "    print(f\"IV: [{iv_min:.3f}, {iv_max:.3f}]\")\n",
    "\n",
    "verify_data_ranges(train_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
